import streamlit as st
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
import pickle
import numpy as np
import time
import plotly.graph_objects as go
from urllib.parse import urlparse, urlunparse, parse_qs, urlencode, unquote
import string
import re
import math
from collections import Counter
from preprocessing import URLPreprocessor 
import pandas as pd
import textwrap

# ==========================================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„Ø«ÙˆØ§Ø¨Øª
# ==========================================
st.set_page_config(page_title="Deep Learning Architecture", layout="wide", page_icon="ğŸ§¬")

def load_css(file_name):
    try:
        with open(file_name) as f:
            st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)
    except FileNotFoundError:
        pass 

load_css("style.css")

# ++++++++++++++++++++++++++++++++++++++++++
# [Ø¥Ø¶Ø§ÙØ© Ø¬Ø¯ÙŠØ¯Ø©]: Ø³ØªØ§ÙŠÙ„ Ø®Ø§Øµ Ù„Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ
# ++++++++++++++++++++++++++++++++++++++++++
st.markdown("""
<style>
    .url-text-display {
        font-family: 'Courier New', monospace;
        font-size: 20px;
        letter-spacing: 2px;
        color: #e0e0e0;
        background-color: #252d3d;
        padding: 15px;
        border-radius: 8px;
        border: 1px solid #4A5568;
        white-space: nowrap;
        overflow-x: auto;
        margin-bottom: 10px;
    }
    .cnn-window-highlight {
        background-color: #e53e3e; /* Ø£Ø­Ù…Ø± */
        color: white;
        padding: 2px 0;
        border-radius: 4px;
        font-weight: bold;
        box-shadow: 0 0 10px #e53e3e;
    }
    .risk-high-text { color: #FC8181; font-weight: bold; }
    .risk-low-text { color: #68D391; font-weight: bold; }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. ÙƒÙ„Ø§Ø³ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
# ==========================================
pre = URLPreprocessor()

# ==========================================
# 3. ØªÙˆÙƒÙŠÙ†Ø§ÙŠØ²Ø± Ø§Ù„Ø¹Ø±Ø¶
# ==========================================
class RealTokenizerWrapper:
    def __init__(self, preprocessor):
        self.pre = preprocessor
    def texts_to_sequences(self, texts):
        return [self.pre.char_encode(t) for t in texts]

tokenizer = RealTokenizerWrapper(pre)

# ==========================================
# 4. Ø¯Ø§Ù„Ø© ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø±Ø§Ø¨Ø·
# ==========================================
def format_url(input_url):
    has_protocol = "://" in input_url
    temp_url = input_url if has_protocol else "http://" + input_url
    parsed = urlparse(temp_url)
    path_parts = [p for p in parsed.path.split('/') if p]
    limited_path = "/".join(path_parts[:2])
    new_path = "/" + limited_path if limited_path else ""
    formatted_url = urlunparse((
        parsed.scheme, parsed.netloc, new_path, '', '', ''
    ))
    if not has_protocol:
         formatted_url = formatted_url.replace(f"{parsed.scheme}://", "", 1)
    return formatted_url.rstrip('/') 

# ==========================================
# 5. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯
# ==========================================
@st.cache_resource
def load_resources():
    try:
        # ğŸ”´ Ù‡Ø§Ù…: ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø²Ùƒ
        model_path = r'C:\Users\mohammad alsarese\Downloads\deep_Streamlt\best_url_model (2)_final.keras' 
        scaler_path = r'C:\Users\mohammad alsarese\Downloads\deep_Streamlt\scaler (2).pickle'
        
        model = load_model(model_path)
        with open(scaler_path, 'rb') as handle:
            scaler = pickle.load(handle)
            
        return model, scaler
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª! ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…Ø³Ø§Ø± (Path).\nØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£: {e}")
        return None, None

model, scaler = load_resources()

# ==========================================
# Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø© (Ø§Ù„Ù…Ø¹Ø¯Ù„Ø© Ù„ØªØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„)
# ==========================================

# --- Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„ØªÙ†Ø¸ÙŠÙ HTML ---
# ==========================================
# Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© (Advanced Visualization)
# ==========================================

def render_clean(container, html_content):
    lines = [line.strip() for line in html_content.split('\n') if line.strip()]
    container.markdown("".join(lines), unsafe_allow_html=True)

def simulate_cnn_layer(url_text, real_prediction_score):
    st.markdown("### ğŸ•µï¸â€â™‚ï¸ 1. CNN Feature Extraction & Max Pooling")
    st.info("Here we visualize the Conv1D Filters scanning patterns, followed by Max Pooling selecting the strongest features.")
    
    container = st.empty()
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø©
    is_phishing = real_prediction_score > 0.5
    # ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù„Ù„ØªØ£Ø«ÙŠØ± Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ø¹Ø±ÙˆØ¶Ø© (Ù„Ù„Ù…Ø­Ø§ÙƒØ§Ø© ÙÙ‚Ø·)
    triggers = ["log", "pay", "sec", "acc", "bank", "upd", "verify", "lim"]
    
    # 1. Ù…Ø±Ø­Ù„Ø© Ø§Ù„ÙÙ„Ø§ØªØ± (Convolution)
    # ------------------------------------------------
    feature_map = []
    window_size = 4
    stride = 1
    
    # Ø¥Ø¨Ø·Ø§Ø¡ Ø§Ù„Ø­Ø±ÙƒØ©
    delay = 0.3 
    
    for i in range(0, len(url_text) - window_size + 1, stride):
        chunk = url_text[i:i+window_size]
        
        # Ø­Ø³Ø§Ø¨ Ø±Ù‚Ù… (Activation) Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆÙ‚Ø±Ø§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
        base_val = np.random.uniform(0.1, 0.4)
        if any(t in chunk.lower() for t in triggers):
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø®Ø¨ÙŠØ« ÙˆØ§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙƒØ´ÙÙ‡ØŒ Ù†Ø¹Ø·ÙŠ Ø±Ù‚Ù… Ø¹Ø§Ù„ÙŠ
            if is_phishing:
                base_val = np.random.uniform(2.5, 4.0) # High Activation
            else:
                base_val = np.random.uniform(0.5, 1.2) # Suppressed activation (Context saved it)
        
        feature_map.append(base_val)
        
        # Ù„ÙˆÙ† Ø§Ù„Ø®Ù„ÙÙŠØ© Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ©
        bg_color = "#2D3748"
        border_color = "#4A5568"
        if base_val > 2.0:
            border_color = "#F56565" # Red border for high activation
            bg_color = "#3B1818"

        html = f"""
        <div style="font-family: 'Courier New'; background: #1A202C; padding: 20px; border-radius: 10px; border: 1px solid #4A5568;">
            <div style="color: #A0AEC0; font-size: 14px; margin-bottom: 10px;">LAYER 1: CONV1D (128 Filters) - Scanning...</div>
            
            <div style="font-size: 24px; letter-spacing: 3px; margin-bottom: 20px;">
                <span style="opacity: 0.5;">{url_text[:i]}</span>
                <span style="border: 3px solid {border_color}; padding: 2px 5px; color: white; background: {bg_color}; font-weight: bold; border-radius: 5px;">
                    {chunk}
                </span>
                <span style="opacity: 0.5;">{url_text[i+window_size:]}</span>
            </div>

            <div style="display: flex; align-items: center; gap: 10px;">
                <div style="font-size: 16px; color: white;">Neuron Activation:</div>
                <div style="font-size: 28px; font-weight: bold; color: {border_color};">
                    {base_val:.4f}
                </div>
            </div>
            <div style="font-size: 12px; color: #718096; margin-top: 5px;">(Higher number = Suspicious Pattern Detected)</div>
        </div>
        """
        render_clean(container, html)
        time.sleep(delay)

    # 2. Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± (Max Pooling)
    # ------------------------------------------------
    time.sleep(0.5)
    st.toast("Applying Max Pooling (Pool Size = 2)...")
    
    # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ¹Ø±Ø¶ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±
    pooled_values = []
    
    # Ù†Ø£Ø®Ø° ÙƒÙ„ Ù‚ÙŠÙ…ØªÙŠÙ† Ù…Ø¹ Ø¨Ø¹Ø¶ (Pool Size = 2)
    pairs = [feature_map[i:i+2] for i in range(0, len(feature_map), 2)]
    
    for pair in pairs:
        if len(pair) < 2: continue # ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø¨Ù‚Ø§ÙŠØ§
        
        v1, v2 = pair[0], pair[1]
        winner = max(v1, v2)
        pooled_values.append(winner)
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ù„Ù„ÙØ§Ø¦Ø² ÙˆØ§Ù„Ø®Ø§Ø³Ø±
        c1 = "#F56565" if v1 == winner and v1 > 1.5 else ("#48BB78" if v1 == winner else "#718096")
        c2 = "#F56565" if v2 == winner and v2 > 1.5 else ("#48BB78" if v2 == winner else "#718096")
        
        op1 = "1.0" if v1 == winner else "0.3"
        op2 = "1.0" if v2 == winner else "0.3"
        
        scale1 = "1.2" if v1 == winner else "0.9"
        scale2 = "1.2" if v2 == winner else "0.9"

        html_pool = f"""
        <div style="font-family: 'Courier New'; background: #1A202C; padding: 20px; border-radius: 10px; border: 1px solid #9F7AEA; text-align: center;">
            <div style="color: #9F7AEA; font-size: 16px; font-weight: bold; margin-bottom: 20px;">LAYER 3: MAX POOLING (Selection)</div>
            <div style="display: flex; justify-content: center; gap: 40px; align-items: center;">
                
                <div style="text-align: center; opacity: {op1}; transform: scale({scale1}); transition: 0.3s;">
                    <div style="font-size: 14px; color: #A0AEC0;">Input A</div>
                    <div style="border: 2px solid {c1}; padding: 10px; width: 80px; font-weight: bold; color: white; border-radius: 8px;">{v1:.2f}</div>
                </div>

                <div style="font-size: 20px; color: #718096;">VS</div>

                <div style="text-align: center; opacity: {op2}; transform: scale({scale2}); transition: 0.3s;">
                    <div style="font-size: 14px; color: #A0AEC0;">Input B</div>
                    <div style="border: 2px solid {c2}; padding: 10px; width: 80px; font-weight: bold; color: white; border-radius: 8px;">{v2:.2f}</div>
                </div>
            </div>

            <div style="margin-top: 20px;">
                <div style="font-size: 30px;">â¬‡ï¸</div>
                <div style="background: #9F7AEA; color: white; padding: 5px 20px; border-radius: 20px; display: inline-block; margin-top: 10px; font-weight: bold;">
                    Selected: {winner:.2f}
                </div>
            </div>
        </div>
        """
        render_clean(container, html_pool)
        time.sleep(0.6) # Ø£Ø¨Ø·Ø£ Ø¹Ø´Ø§Ù† ØªÙ„Ø­Ù‚ ØªØ´ÙˆÙ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±

    st.success(f"âœ… Pooling Complete. Reduced features from {len(feature_map)} to {len(pooled_values)}.")


def simulate_gru_layer(url_text):
    st.markdown("### ğŸ§  2. Bi-Directional GRU (Context Layer)")
    st.info("Bi-GRU reads the URL in two directions simultaneously to understand context (e.g., 'secure' before 'bank' vs 'bank' before 'secure').")
    
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø´Ø§Ø´Ø©
    col_fwd, col_bwd = st.columns(2)
    
    ph_fwd = col_fwd.empty()
    ph_bwd = col_bwd.empty()
    
    chars = list(url_text)
    length = len(chars)
    steps = min(length, 15) # ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ù„Ù„Ø¹Ø±Ø¶
    
    # Forward Pass Logic
    fwd_text = ""
    
    # Backward Pass Logic
    bwd_text = ""
    
    # Ø­Ù„Ù‚Ø© Ø§Ù„ØªÙƒØ±Ø§Ø± (Ù„Ù„Ø§Ø«Ù†ÙŠÙ† Ù…Ø¹ Ø¨Ø¹Ø¶)
    for i in range(steps):
        # 1. ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø£Ù…Ø§Ù…ÙŠ (Forward)
        char_f = chars[i]
        fwd_text += char_f
        
        html_fwd = f"""
        <div style="background: #0D1117; border: 1px solid #238636; border-radius: 8px; padding: 10px; height: 150px;">
            <div style="color: #238636; font-weight: bold; margin-bottom: 10px;">â¡ï¸ FORWARD GRU (Past Context)</div>
            <div style="font-family: monospace; color: #58A6FF; font-size: 18px; letter-spacing: 2px;">
                {fwd_text}<span style="color: #238636; text-decoration: blink;">_</span>
            </div>
            <div style="margin-top: 20px; font-size: 12px; color: #8B949E;">
                Memory State: Updating based on prefix...
            </div>
            <div style="width: {(i+1)/steps*100}%; height: 4px; background: #238636; margin-top: 10px; transition: 0.1s;"></div>
        </div>
        """
        render_clean(ph_fwd, html_fwd)
        
        # 2. ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹ÙƒØ³ÙŠ (Backward)
        # Ù†Ù‚Ø±Ø£ Ù…Ù† Ø¢Ø®Ø± Ø§Ù„Ø±Ø§Ø¨Ø·
        char_b = chars[length - 1 - i]
        bwd_text = char_b + bwd_text
        
        html_bwd = f"""
        <div style="background: #0D1117; border: 1px solid #A371F7; border-radius: 8px; padding: 10px; height: 150px;">
            <div style="color: #A371F7; font-weight: bold; margin-bottom: 10px; text-align: right;">BACKWARD GRU (Future Context) â¬…ï¸</div>
            <div style="font-family: monospace; color: #F0883E; font-size: 18px; letter-spacing: 2px; text-align: right;">
                <span style="color: #A371F7; text-decoration: blink;">_</span>{bwd_text}
            </div>
            <div style="margin-top: 20px; font-size: 12px; color: #8B949E; text-align: right;">
                Memory State: Updating based on suffix...
            </div>
             <div style="width: 100%; display: flex; justify-content: flex-end;">
                <div style="width: {(i+1)/steps*100}%; height: 4px; background: #A371F7; margin-top: 10px; transition: 0.1s;"></div>
            </div>
        </div>
        """
        render_clean(ph_bwd, html_bwd)
        
        time.sleep(0.2) # Ø³Ø±Ø¹Ø© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©
        
    # Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø¯Ù…Ø¬ (Concatenation)
    st.markdown("#### ğŸ”— Concatenation (Feature Fusion)")
    fusion_html = """
    <div style="display: flex; justify-content: center; align-items: center; gap: 20px; margin-top: 10px;">
        <div style="background: #238636; color: white; padding: 10px 20px; border-radius: 5px;">Forward Vector (h_t)</div>
        <div style="font-size: 24px;">â•</div>
        <div style="background: #A371F7; color: white; padding: 10px 20px; border-radius: 5px;">Backward Vector (h'_t)</div>
        <div style="font-size: 24px;">ğŸŸ°</div>
        <div style="background: linear-gradient(90deg, #238636, #A371F7); color: white; padding: 10px 30px; border-radius: 5px; font-weight: bold; border: 1px solid white;">Full Context Representation</div>
    </div>
    """
    st.markdown(fusion_html, unsafe_allow_html=True)
    time.sleep(1.0)

# ==========================================
# 6. Ù…Ø­Ø±Ùƒ Ø§Ù„Ø£Ù†ÙŠÙ…ÙŠØ´Ù† Ø§Ù„Ø¥Ø¶Ø§ÙÙŠ
# ==========================================
def run_full_simulation(url_text, tokenizer):
    # Ù…Ø­Ø§ÙƒØ§Ø© Ø¨Ø³ÙŠØ·Ø© Ù„Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„ÙƒØ§Ù…Ù„
    chars = list(url_text)
    seq = tokenizer.texts_to_sequences([url_text])[0]
    display_len = min(len(chars), 20)
    
    step_placeholder = st.empty()
    
    # Ø¹Ø±Ø¶ Ø³Ø±ÙŠØ¹ Ù„Ù„Ù…Ø±Ø§Ø­Ù„ Ø¯ÙˆÙ† Ø§Ù†ØªØ¸Ø§Ø± Ø·ÙˆÙŠÙ„
    html_block = f"""
    <div style="display:flex; justify-content:space-around; background:#2D3748; padding:15px; border-radius:10px; margin-top:10px;">
        <div style="text-align:center; color:#63B3ED;"><b>1. Input</b><br>{url_text[:15]}...</div>
        <div style="text-align:center; color:#9F7AEA;"><b>2. Embedding</b><br>Vector Space</div>
        <div style="text-align:center; color:#48BB78;"><b>3. CNN+GRU</b><br>Feature Extraction</div>
        <div style="text-align:center; color:#F56565;"><b>4. Dense</b><br>Classification</div>
    </div>
    """
    step_placeholder.markdown(html_block, unsafe_allow_html=True)

# ==========================================
# 7. Ø¯Ø§Ù„Ø© Ø±Ø³Ù… Ø§Ù„Ø¹Ø¯Ø§Ø¯
# ==========================================
def plot_gauge(current_value):
    score_val = int(current_value)
    if score_val < 33:
        label_text, title_color = "LOW RISK", "#4CAF50"
    elif score_val < 66:
        label_text, title_color = "MODERATE", "#FF9800"
    else:
        label_text, title_color = "SEVERE RISK", "#F44336"

    fig = go.Figure(go.Indicator(
        mode = "gauge+number",
        value = score_val,
        domain = {'x': [0, 1], 'y': [0, 1]},
        title = {'text': f"<b>{label_text}</b>", 'font': {'size': 26, 'color': title_color}},
        number = {'suffix': "%", 'font': {'size': 60, 'color': "white", 'family': "Arial Black"}},
        gauge = {
            'axis': {'range': [None, 100], 'visible': False}, 
            'bar': {'color': "rgba(0,0,0,0)"}, 
            'bgcolor': "rgba(0,0,0,0)",
            'borderwidth': 0,
            'steps': [
                {'range': [0, 33], 'color': "#4CAF50"}, 
                {'range': [33, 66], 'color': "#FF9800"}, 
                {'range': [66, 100], 'color': "#F44336"} 
            ],
            'threshold': {'line': {'color': "black", 'width': 8}, 'thickness': 0.75, 'value': score_val}
        }
    ))
    fig.update_layout(paper_bgcolor="rgba(0,0,0,0)", font={'color': "white"}, height=400, margin=dict(l=30, r=30, t=60, b=20))
    return fig

# ==========================================
# 8. Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ (Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„Ù…Ø¹Ø¯Ù„)
# ==========================================
st.title("ğŸ›¡ï¸ AI Phishing Detector: Deep Dive")
st.markdown("##### Hybrid CNN + Bi-GRU Neural Network Visualization")

url_input_raw = st.text_input("ğŸ”— Enter URL to Analyze:", placeholder="http://example-bank-login.com")

if st.button("ğŸš€ Analyze URL") and url_input_raw:
    if not model:
        st.error("âš ï¸ Model files not found! Please check the file paths in the code.")
    else:
        # 1. Ø§Ù„ØªØ¬Ù‡ÙŠØ² ÙˆØ§Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„ÙØ¹Ù„ÙŠ Ø£ÙˆÙ„Ø§Ù‹ (Ù‚Ø¨Ù„ Ø§Ù„Ø±Ø³Ù…)
        url_input = format_url(url_input_raw)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        seq, fet, _ = pre.process(url_input)
        seq = seq.reshape(1, -1)
        fet = fet.reshape(1, -1)
        fet = scaler.transform(fet)
        
        # Ø§Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
        prediction = model.predict([seq, fet], verbose=0)[0][0]
        final_score = int(prediction * 100)
        
        # ++++++++++++++++++++++++++++++++++++++++++
        # 2. ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ (Ù…Ø¹ ØªÙ…Ø±ÙŠØ± Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù„ØªØµØ­ÙŠØ­ Ø§Ù„Ø±Ø³Ù…)
        # ++++++++++++++++++++++++++++++++++++++++++
        simulate_cnn_layer(url_input, prediction) # Ù†Ù…Ø±Ø± Ø§Ù„Ù€ prediction Ù‡Ù†Ø§
        simulate_gru_layer(url_input)
        st.divider() 

        # 3. Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        run_full_simulation(url_input, tokenizer)
        
        c1, c2 = st.columns([1, 1])
        with c1:
            st.subheader("4. FINAL RISK ASSESSMENT")
            gauge_placeholder = st.empty()
            # Ø£Ù†ÙŠÙ…ÙŠØ´Ù† Ø³Ø±ÙŠØ¹ Ù„Ù„Ø¹Ø¯Ø§Ø¯
            fig = plot_gauge(final_score)
            gauge_placeholder.plotly_chart(fig, use_container_width=True)
            
        with c2:
            st.markdown("<br><br><br>", unsafe_allow_html=True)
            if prediction > 0.5:
                st.error(f"### ğŸš¨ PHISHING DETECTED")
                st.markdown(f"**Threat Level:** Severe\n\n**Confidence:** {final_score}%")
                st.info("The model detected suspicious patterns consistent with phishing attacks.")
            else:
                st.success(f"### âœ… WEBSITE IS SAFE")
                st.markdown(f"**Threat Level:** Low\n\n**Safety Score:** {100-final_score}%")
                st.info("No malicious patterns detected in the URL structure.")